{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e30de4",
   "metadata": {
    "id": "90e30de4"
   },
   "source": [
    "# Face Detection - YOLOv8n\n",
    "# Face Embedding and Recognition - FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OwMNKbO900Bk",
   "metadata": {
    "id": "OwMNKbO900Bk"
   },
   "outputs": [],
   "source": [
    "# Installation\n",
    "!pip install deepface\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cb4ca3",
   "metadata": {
    "collapsed": true,
    "id": "c4cb4ca3"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1pyUec3wObjZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pyUec3wObjZ",
    "outputId": "6f23e268-9042-46c1-d50a-169027628222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "EwxEWjKhZrGC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwxEWjKhZrGC",
    "outputId": "54bc1240-9d5b-4cf5-fd94-14da48f0daf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vid1: 1280 720 13.057954427218812 251\n",
      "Vid2: 1280 720 11.926205536601675 7687\n",
      "7938\n"
     ]
    }
   ],
   "source": [
    "# Get videos info\n",
    "total = 0\n",
    "for i in range(1,3):\n",
    "    input_video = f'/content/drive/MyDrive/Videos/Vid{i}.mp4'\n",
    "    cap = cv2.VideoCapture(input_video)  # input video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # input video FPS\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_number_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f'Vid{i}:' ,W,H,fps,total_number_of_frames)\n",
    "    total += total_number_of_frames\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W17w8Eq7sxMI",
   "metadata": {
    "id": "W17w8Eq7sxMI"
   },
   "source": [
    "### Extract Face Embedings and Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TC_s4mQWzcXs",
   "metadata": {
    "id": "TC_s4mQWzcXs"
   },
   "source": [
    "> First read the video and detect the faces in the first frame,\n",
    "> save them in FaceBank,\n",
    "\n",
    "> For next frames check the similarity with the prevoius frame\n",
    "> if the Face matched so no action is needed                        \n",
    "\n",
    "> If the Face didnt match, then check the similarity with the FaceBank,\n",
    "> ---> If matched with FaceBank, no action is needed,\n",
    "> ---> If didnt matched, that is a new Face and should be save in the facceBank, and gets an ID\n",
    "\n",
    "> **Hint: For final code we should Save several faces area for each person and Tune the Threshold parameter! Fine-Tuning Detection Model can Enhance the Perfomance as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oRbLaUF4znxk",
   "metadata": {
    "id": "oRbLaUF4znxk"
   },
   "outputs": [],
   "source": [
    "# This function compute cosine distance between two vectors\n",
    "#(cosine distance = 1 - cosine similarity)\n",
    "def comp_cosine_distance(source_representation, test_representation):\n",
    "\n",
    "    a = np.dot(source_representation, test_representation)\n",
    "    b = np.linalg.norm(source_representation)\n",
    "    c = np.linalg.norm(test_representation)\n",
    "    return 1 - a / (b * c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pqvJdj17CUmR",
   "metadata": {
    "id": "pqvJdj17CUmR"
   },
   "outputs": [],
   "source": [
    "def show_face_bank(face_bank):\n",
    "    for i, face in enumerate(face_bank):\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'ID: {i}')\n",
    "        plt.axis('off')\n",
    "        plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "t6SiJb7ow5F7",
   "metadata": {
    "id": "t6SiJb7ow5F7"
   },
   "outputs": [],
   "source": [
    "# The main function: Face Detection (YOLOv8n-face) --> Face Embedding (FaceNet)\n",
    "# --> Check Similarity (cosine similarity) --> Face Matching.\n",
    "\n",
    "def find_unique_persons(thresh, video_path):\n",
    "\n",
    "    # Load YOLO face detection model\n",
    "    model = YOLO(\"/content/drive/MyDrive/yolov8n-face.pt\", task = 'pose')\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    # FaceBank list\n",
    "    face_bank = []\n",
    "    results_list = []\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            frame_counter += 1\n",
    "            results = model(frame)\n",
    "            results_list.append(results[0])\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "\n",
    "        # save the faces in facebank correpond to the FIRST FRAME\n",
    "        if frame_counter == 1:\n",
    "\n",
    "          # loop through detected faces\n",
    "          for face_coords in results[0].boxes.xywh:\n",
    "              x,y,w,h = np.array(face_coords).astype(int)\n",
    "              face_area = frame[y-h//2:y+h//2,x-w//2:x+w//2,:]\n",
    "              face_bank.append(face_area)\n",
    "\n",
    "          # save the current frame for similarity check with next frame\n",
    "          prev_frame = np.copy(frame)\n",
    "\n",
    "        else:\n",
    "          # A list for save current frame face area\n",
    "          current_frame_face_areas = []\n",
    "\n",
    "          # loop through detected faces\n",
    "          for face_coords in results[0].boxes.xywh:\n",
    "              x,y,w,h = np.array(face_coords).astype(int)\n",
    "              face_area = frame[y-h//2:y+h//2,x-w//2:x+w//2,:]\n",
    "              current_frame_face_areas.append(face_area)\n",
    "\n",
    "\n",
    "          # extract results for prev Frame\n",
    "          prev_results = model(prev_frame)\n",
    "          prev_frame_face_areas = []\n",
    "          # loop through detected faces\n",
    "          for face_coords in prev_results[0].boxes.xywh:\n",
    "              x,y,w,h = np.array(face_coords).astype(int)\n",
    "              face_area = prev_frame[y-h//2:y+h//2,x-w//2:x+w//2,:]\n",
    "              prev_frame_face_areas.append(face_area)\n",
    "\n",
    "\n",
    "          # check similarity between current frame and the previous one/facebank\n",
    "          # loop through the  current faces\n",
    "          for face_area in current_frame_face_areas:\n",
    "\n",
    "              match_flag = False\n",
    "              face_area_embedding_objs = DeepFace.represent(\n",
    "                  img_path = cv2.resize(face_area, (160,160)),\n",
    "                  model_name ='Facenet', enforce_detection=False)\n",
    "              face_area_embedding = face_area_embedding_objs[0]['embedding']\n",
    "\n",
    "              # check similarity with prev frame\n",
    "              for prev_face_area in prev_frame_face_areas:\n",
    "\n",
    "                  prev_embedding_objs = DeepFace.represent(\n",
    "                      img_path = cv2.resize(prev_face_area, (160,160)),\n",
    "                      model_name ='Facenet', enforce_detection=False)\n",
    "                  prev_face_area_embedding = prev_embedding_objs[0]['embedding']\n",
    "\n",
    "                  # compute cosine distance\n",
    "                  dist = comp_cosine_distance(\n",
    "                      face_area_embedding, prev_face_area_embedding)\n",
    "\n",
    "                  if dist<= thresh: # it means the face is matched\n",
    "                      match_flag = True\n",
    "                      break\n",
    "\n",
    "\n",
    "              # check similarity with face bank\n",
    "              # it means the face is not matched with prevframe\n",
    "              # so should be check with FaceBank\n",
    "              if match_flag == False:\n",
    "                  for saved_face in face_bank:\n",
    "\n",
    "                      saved_embedding_objs = DeepFace.represent(\n",
    "                          img_path = cv2.resize(saved_face, (160,160)),\n",
    "                          model_name ='Facenet', enforce_detection=False)\n",
    "                      saved_face_area_embedding = saved_embedding_objs[0]['embedding']\n",
    "\n",
    "                      # compute cosine distance\n",
    "                      dist = comp_cosine_distance(\n",
    "                          face_area_embedding, saved_face_area_embedding)\n",
    "\n",
    "                      # it means the face is matched with facebank\n",
    "                      if dist<= thresh:\n",
    "                        match_flag = True\n",
    "                        break\n",
    "\n",
    "              # New Face is Recognised!\n",
    "              # it means the face is not matched even with the facebank\n",
    "              # so its a new face and should be added to facebank\n",
    "              if match_flag == False:\n",
    "                  face_bank.append(face_area)\n",
    "\n",
    "          # save the current frame for similarity check with next frame\n",
    "          prev_frame = np.copy(frame)\n",
    "\n",
    "          if frame_counter%50 == 0:\n",
    "              print('*****************',frame_counter)\n",
    "              print('*****************',len(face_bank))\n",
    "\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    return face_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "BvL6LaQgw5Dw",
   "metadata": {
    "id": "BvL6LaQgw5Dw"
   },
   "outputs": [],
   "source": [
    "face_bank_vid1 = find_unique_persons(\n",
    "    thresh=0.3, video_path=\"/content/drive/MyDrive/Videos/Vid1.mp4\")\n",
    "print(len(face_bank_vid1))\n",
    "show_face_bank(face_bank_vid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "-K-q9rbgyztV",
   "metadata": {
    "id": "-K-q9rbgyztV"
   },
   "outputs": [],
   "source": [
    "face_bank_vid2 = find_unique_persons(\n",
    "    thresh=0.3, video_path=\"/content/drive/MyDrive/Videos/Vid2.mp4\")\n",
    "print(len(face_bank_vid2))\n",
    "show_face_bank(face_bank_vid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QKekkZzmQeJL",
   "metadata": {
    "id": "QKekkZzmQeJL"
   },
   "source": [
    "## Problems:\n",
    "1- Recognize a person as different ones!\n",
    "\n",
    "2- False Positive and False Negative Detections!\n",
    "### Primary Solutions\n",
    "- Set Threshold properly\n",
    " - Vid1 Results:\n",
    "    -  thresh = 0.15 >>> 29 persons\n",
    "    -  thresh = 0.3 >>> 8 persons\n",
    " - Vid2 Results:\n",
    "    -  thresh = 0.15 >>>\n",
    "    -  thresh = 0.3 >>>\n",
    "- Save several faces area of a person (TODO)\n",
    "- Fine-Tuning Face Detection Model (TODO)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
